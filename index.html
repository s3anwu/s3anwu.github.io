<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Sean Wu</title>

    <meta name="author" content="Sean Wu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Sean Wu
                </p>
                <p>
                I’m a Master’s student at <a href="https://www.ethz.ch">ETH Zurich</a>, specializing in computer vision and machine learning.
                I currently work on neural rendering with <a href="https://people.ee.ethz.ch/~csakarid/">Dr. Christos Sakaridis</a> and <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjg3LC0xOTcxNDY1MTc4.html">Prof. Luc Van Gool</a> at the <a href="https://www.vision.ee.ethz.ch">ETH Computer Vision Lab</a>.
                Previously, I studied <a href="https://engsci.utoronto.ca/">Engineering Science</a> at the <a href="https://www.utoronto.ca">University of Toronto</a>, where I worked on perception for autonomous driving with <a href="https://starslab.ca/people/prof-jonathan-kelly/">Prof. Jonathan Kelly</a> and the <a href="https://www.autodrive.utoronto.ca/">aUToronto</a> self-driving car team.

                </p>
                <p>
                Outside of research, I dabble in learning languages, running, and hiking.
                </p>
                <p style="text-align:center">
                  <a href="mailto:seanwu@ethz.ch">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=fodBgkUAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/s3anwu/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/wu-sean/">Linkedin</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/profile.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                I’m broadly interested in the intersection of vision + graphics, particularly in 3D scene understanding and generation. My recent work focuses on neural rendering, multi-sensor perception, and visual inductive biases. I especially enjoy: (1) application-driven problems (e.g. photorealistic digital humans and autonomous driving) and (2) leveraging theory (e.g physics, graphics, optimization, etc) to guide data-driven learning.
                </p>
                <p>
                * denotes equal contribution
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
              <td style="padding:16px;width:25%;vertical-align:middle">
                <img src="images/pbrnerf_promo.png" alt="pbrnerf" width="250">
              </td>
              <td style="padding:8px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2412.09680">
                  <span class="papertitle">PBR-NeRF: Inverse Rendering with Physics-Based Neural Fields</span>
                </a>
                <br>
                <strong>Sean Wu</strong>,
                <a href="https://www.linkedin.com/in/shamik-basu-1b998a85/">Shamik Basu</a>,
                <a href="https://people.ee.ethz.ch/~timbr/">Tim Broedermann</a>,
                <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjg3LC0xOTcxNDY1MTc4.html">Luc Van Gool</a>,
                <a href="https://people.ee.ethz.ch/~csakarid/">Christos Sakaridis</a>
                <br>
                <em>CVPR</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2412.09680">paper</a>
                /
                <a href="https://github.com/s3anwu/pbrnerf">project page</a>
                /
                <a href="https://github.com/s3anwu/pbrnerf">code</a>
                <span style="display: inline-block; transform: translateY(-0.5px);">
                  <iframe
                    src="https://ghbtns.com/github-btn.html?user=s3anwu&repo=pbrnerf&type=star&count=true&size=small"
                    frameborder="0"
                    scrolling="0"
                    width="100"
                    height="20"
                    title="GitHub"
                    style="vertical-align: middle;"
                  ></iframe>
                </span>
                <p></p>
                <p>
                Physics-based priors help constrain the ill-posed inverse rendering problem, allowing neural fields to more accurately estimate geometry, lighting, and BRDF-based materials.
                </p>
              </td>
            </tr>


          <tr>
              <td style="padding:16px;width:25%;vertical-align:middle">
                <img src="images/imlp_promo.png" alt="imlp" width="250">
              </td>
              <td style="padding:8px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2410.09655">
                  <span class="papertitle">Interpolated-MLPs: Controllable Inductive Bias</span>
                </a>
                <br>
                <strong>Sean Wu</strong>*,
                <a href="https://www.linkedin.com/in/jordan-hong/">Jordan Hong</a>*,
                <a href="https://www.linkedin.com/in/keyu-bai-563296277/">Keyu Bai</a>*,
                <a href="https://www.linkedin.com/in/gregor-bachmann-27a728180/">Gregor Bachmann</a>
                <br>
                <em>ICML Workshop: High-dimensional Learning Dynamics</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2410.09655">paper</a>
                <p></p>
                <p>
                We empirically study visual inductive biases by interpolating MLP weights with structured weight matrices (CNNs, MLP-Mixers) and measuring test performance.
                </p>
              </td>
            </tr>



          <tr>
              <td style="padding:16px;width:25%;vertical-align:middle">
                <img src="images/autolights_promo.jpg" alt="autolights" width="250">
              </td>
              <td style="padding:8px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2305.08673">
                  <span class="papertitle">aUToLights: A Robust Multi-Camera Traffic Light Detection and Tracking System</span>
                </a>
                <br>
                <strong>Sean Wu</strong>,
                <a href="https://www.linkedin.com/in/nicole-amenta/">Nicole Amenta</a>,
                <a href="https://www.linkedin.com/in/jiachenjason-zhou/">Jiachen Zhou</a>,
                <a href="https://sandropapais.github.io/">Sandro Papais</a>,
                <a href="https://starslab.ca/people/prof-jonathan-kelly/">Jonathan Kelly</a>
                <br>
                <em>Conference on Robots and Vision</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2305.08673">paper</a>
                <p></p>
                <p>
                Multiple cameras + CNNs + HD map + HMM filtering enable robust real-time traffic light perception for autonomous vehicles.
                </p>
              </td>
            </tr>


          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Thank you to <a href="https://jonbarron.info/">Jon Barron</a> for open-sourcing his website.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
